{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from src.model import CustomResNet\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "def time_it(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_time_it(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Function '{func.__name__}' executed in {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper_time_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training without pin_memory:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 98.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'train_loop' executed in 3.1836 seconds\n",
      "Training with pin_memory:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 112.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'train_loop' executed in 2.7848 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5481895902381606, 0.6857553305336461, 54.82)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dummy dataset\n",
    "data = torch.randn(10000, 3, 224, 224)  # 10000 images, 3 channels, 224x224 size\n",
    "labels = torch.randint(0, 2, (10000,))  # Binary labels\n",
    "\n",
    "dataset = TensorDataset(data, labels)\n",
    "batch_size = 32\n",
    "\n",
    "def calc_accuracy(correct, total):\n",
    "    return 100 * correct / total\n",
    "\n",
    "def calc_conf_per_class(class_label, preds, labels):\n",
    "    tp = ((preds == class_label) & (labels == class_label)).sum().item()\n",
    "    fp = ((preds == class_label) & (labels != class_label)).sum().item()\n",
    "    fn = ((preds != class_label) & (labels == class_label)).sum().item()\n",
    "    return tp, fp, fn\n",
    "\n",
    "def calc_f1(tp, fp, fn):\n",
    "    precision = tp / (tp + fp + 1e-10)\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "    return 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "@time_it\n",
    "def train_loop(model, train_loader, criterion, optimizer, num_classes, device, accumulation_steps=4):\n",
    "    model.train()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    train_running_loss = 0\n",
    "    train_total_samples = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    tp = np.zeros(num_classes)\n",
    "    fp = np.zeros(num_classes)\n",
    "    fn = np.zeros(num_classes)\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, total=len(train_loader))):\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_running_loss += loss.item()\n",
    "        train_total_samples += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for class_label in range(num_classes):\n",
    "            true_pos, false_pos, false_neg = calc_conf_per_class(class_label, predicted, labels)\n",
    "            tp[class_label] += true_pos\n",
    "            fp[class_label] += false_pos\n",
    "            fn[class_label] += false_neg\n",
    "\n",
    "    loss = train_running_loss / len(train_loader)\n",
    "    accuracy = calc_accuracy(train_correct, train_total_samples)\n",
    "    f1 = calc_f1(tp, fp, fn)\n",
    "    avg_f1 = f1.mean()\n",
    "\n",
    "    return avg_f1.item(), loss, accuracy\n",
    "\n",
    "# Initialize model, criterion, optimizer\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(16 * 112 * 112, 2)\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Measure performance without pin_memory\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=False)\n",
    "print(\"Training without pin_memory:\")\n",
    "train_loop(model, train_loader, criterion, optimizer, num_classes=2, device=device)\n",
    "\n",
    "# Measure performance with pin_memory\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "print(\"Training with pin_memory:\")\n",
    "train_loop(model, train_loader, criterion, optimizer, num_classes=2, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
