{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -q tcia-utils\n",
    "!pip install -q pydicom\n",
    "# !pip install imageio\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm import tqdm\n",
    "import pydicom as dicom\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from tcia_utils import nbia\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "__dir__ = Path().absolute().parent\n",
    "data_dir =__dir__/\"data\" \n",
    "dcm_dir = data_dir/\"dcm\"\n",
    "masked_data_dir = data_dir/\"masked_cropped\"\n",
    "dataset_dir = data_dir/\"dataset\"\n",
    "augmented_dir = data_dir/\"augmented\"\n",
    "\n",
    "dcm_dir.mkdir(exist_ok=True)\n",
    "masked_data_dir.mkdir(exist_ok=True)\n",
    "augmented_dir.mkdir(exist_ok=True)\n",
    "dataset_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "dcm_extension = \".dcm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 16:22:54,421:INFO:Calling... https://services.cancerimagingarchive.net/nbia-api/services/v1/getSeries with parameters {'Collection': 'CBIS-DDSM'}\n",
      "2024-06-27 16:22:55,264:ERROR:502 Server Error: Bad Gateway for url: https://services.cancerimagingarchive.net/nbia-api/services/v1/getSeries?Collection=CBIS-DDSM\n",
      "2024-06-27 16:22:55,266:INFO:Calling... https://services.cancerimagingarchive.net/nbia-api/services/v1/getSeries with parameters {'Collection': 'CBIS-DDSM'}\n",
      "2024-06-27 16:22:59,099:ERROR:502 Server Error: Bad Gateway for url: https://services.cancerimagingarchive.net/nbia-api/services/v1/getSeries?Collection=CBIS-DDSM\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m   data \u001b[38;5;241m=\u001b[39m nbia\u001b[38;5;241m.\u001b[39mgetSeries(collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBIS-DDSM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m   df_meta_orig \u001b[38;5;241m=\u001b[39m nbia\u001b[38;5;241m.\u001b[39mgetSeries(collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBIS-DDSM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m   df_meta \u001b[38;5;241m=\u001b[39m \u001b[43mdf_meta_orig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m scans in total\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  data = nbia.getSeries(collection = \"CBIS-DDSM\")\n",
    "  df_meta_orig = nbia.getSeries(collection = \"CBIS-DDSM\", format=\"df\")\n",
    "  df_meta = df_meta_orig.copy()\n",
    "  print(f\"There are {len(data)} scans in total\")\n",
    "except TypeError:\n",
    "  print(\"Server unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 16:21:54,324:INFO:Calling... https://services.cancerimagingarchive.net/nbia-api/services/v1/getSeries with parameters {'Collection': 'CBIS-DDSM'}\n",
      "2024-06-27 16:21:55,227:ERROR:502 Server Error: Bad Gateway for url: https://services.cancerimagingarchive.net/nbia-api/services/v1/getSeries?Collection=CBIS-DDSM\n",
      "2024-06-27 16:21:55,229:INFO:Calling... https://services.cancerimagingarchive.net/nbia-api/services/v1/getSeries with parameters {'Collection': 'CBIS-DDSM'}\n",
      "2024-06-27 16:21:58,299:ERROR:502 Server Error: Bad Gateway for url: https://services.cancerimagingarchive.net/nbia-api/services/v1/getSeries?Collection=CBIS-DDSM\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m   data \u001b[38;5;241m=\u001b[39m nbia\u001b[38;5;241m.\u001b[39mgetSeries(collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBIS-DDSM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m   df_meta_orig \u001b[38;5;241m=\u001b[39m nbia\u001b[38;5;241m.\u001b[39mgetSeries(collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCBIS-DDSM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m   df_meta \u001b[38;5;241m=\u001b[39m \u001b[43mdf_meta_orig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m scans in total\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "mass_train = \"https://wiki.cancerimagingarchive.net/download/attachments/22516629/mass_case_description_train_set.csv?version=1&modificationDate=1506796355038&api=v2\"\n",
    "calc_train = \"https://wiki.cancerimagingarchive.net/download/attachments/22516629/calc_case_description_train_set.csv?version=1&modificationDate=1506796349666&api=v2\"\n",
    "calc_test = \"https://wiki.cancerimagingarchive.net/download/attachments/22516629/calc_case_description_test_set.csv?version=1&modificationDate=1506796343686&api=v2\"\n",
    "mass_test = \"https://wiki.cancerimagingarchive.net/download/attachments/22516629/mass_case_description_test_set.csv?version=1&modificationDate=1506796343175&api=v2\"\n",
    "df_mass_train = pd.read_csv(BytesIO(requests.get(mass_train).content))\n",
    "df_mass_test = pd.read_csv(BytesIO(requests.get(mass_test).content))\n",
    "df_calc_train = pd.read_csv(BytesIO(requests.get(calc_train).content))\n",
    "df_calc_test = pd.read_csv(BytesIO(requests.get(calc_test).content))\n",
    "df_mass, df_calc = pd.concat([df_mass_train, df_mass_test]), pd.concat([df_calc_train, df_calc_test])\n",
    "df_orig = pd.concat([df_mass, df_calc])\n",
    "df = df_orig.copy()\n",
    "\n",
    "try:\n",
    "  data = nbia.getSeries(collection = \"CBIS-DDSM\")\n",
    "  df_meta_orig = nbia.getSeries(collection = \"CBIS-DDSM\", format=\"df\")\n",
    "  df_meta = df_meta_orig.copy()\n",
    "  print(f\"There are {len(data)} scans in total\")\n",
    "except TypeError:\n",
    "  print(\"Server unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SeriesDescription</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>ImageCount</th>\n",
       "      <th>PatientID_num</th>\n",
       "      <th>abnorm_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.117041576511324414842...</td>\n",
       "      <td>ROI mask images</td>\n",
       "      <td>RIGHT_CC</td>\n",
       "      <td>2</td>\n",
       "      <td>P_01009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.438738396107617880132...</td>\n",
       "      <td>ROI mask images</td>\n",
       "      <td>RIGHT_MLO</td>\n",
       "      <td>2</td>\n",
       "      <td>P_00061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.767416741131676463382...</td>\n",
       "      <td>ROI mask images</td>\n",
       "      <td>RIGHT_MLO</td>\n",
       "      <td>2</td>\n",
       "      <td>P_00617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.296931352612305599800...</td>\n",
       "      <td>ROI mask images</td>\n",
       "      <td>RIGHT_MLO</td>\n",
       "      <td>2</td>\n",
       "      <td>P_00417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3.6.1.4.1.9590.100.1.2.436657670120353100077...</td>\n",
       "      <td>ROI mask images</td>\n",
       "      <td>LEFT_CC</td>\n",
       "      <td>2</td>\n",
       "      <td>P_01635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SeriesInstanceUID SeriesDescription  \\\n",
       "0  1.3.6.1.4.1.9590.100.1.2.117041576511324414842...   ROI mask images   \n",
       "1  1.3.6.1.4.1.9590.100.1.2.438738396107617880132...   ROI mask images   \n",
       "2  1.3.6.1.4.1.9590.100.1.2.767416741131676463382...   ROI mask images   \n",
       "3  1.3.6.1.4.1.9590.100.1.2.296931352612305599800...   ROI mask images   \n",
       "4  1.3.6.1.4.1.9590.100.1.2.436657670120353100077...   ROI mask images   \n",
       "\n",
       "   PatientID  ImageCount PatientID_num  abnorm_num  \n",
       "0   RIGHT_CC           2       P_01009           1  \n",
       "1  RIGHT_MLO           2       P_00061           1  \n",
       "2  RIGHT_MLO           2       P_00617           1  \n",
       "3  RIGHT_MLO           2       P_00417           1  \n",
       "4    LEFT_CC           2       P_01635           1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir/\"df.csv\", index_col=0)\n",
    "df_meta = pd.read_csv(data_dir/\"df_meta.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_patient(id):\n",
    "  \"\"\"download all data given patient id\"\"\"\n",
    "  patient_dir = dcm_dir/id\n",
    "  patient_dir.mkdir(exist_ok=True)\n",
    "  series_uids = df_meta.query(\"PatientID_num == @id\")['SeriesInstanceUID'].to_list()\n",
    "  nbia.downloadSeries(series_uids, input_type = \"list\", path=str(patient_dir))\n",
    "  return patient_dir\n",
    "\n",
    "def read_dcm(file, plot=False):\n",
    "    ds1 = dicom.dcmread(file)\n",
    "    a = ds1.pixel_array\n",
    "\n",
    "    if plot:\n",
    "        plt.imshow(a, cmap='gray')\n",
    "    return a\n",
    "\n",
    "def get_cropped_img(full_img, mask):\n",
    "    binary_mask = mask //255\n",
    "    masked_image = full_img * binary_mask\n",
    "    coords = np.column_stack(np.where(binary_mask == 1))\n",
    "    x_min, y_min = coords.min(axis=0)\n",
    "    x_max, y_max = coords.max(axis=0)\n",
    "    cropped_image = masked_image[x_min:x_max+1, y_min:y_max+1]\n",
    "    return cropped_image\n",
    "\n",
    "def show_dcm(patient, desc):\n",
    "\n",
    "    df_patient = df_meta.query(\"PatientID_num ==@patient & SeriesDescription == @desc\").copy()\n",
    "    print(df_patient)\n",
    "    for row in df_patient.iterrows():\n",
    "        parent_dir = Path(row[1][\"SeriesInstanceUID\"])\n",
    "        dcm_filenames = parent_dir.glob(\"*.dcm\")\n",
    "        for dcm_filename in dcm_filenames:\n",
    "            dcm_file = parent_dir/dcm_filename\n",
    "            print(dcm_file)\n",
    "            read_dcm(dcm_file, True)\n",
    "\n",
    "\n",
    "def clean_directory(path):\n",
    "    \"\"\"\n",
    "    Recursively delete all files and subdirectories in a given directory.\n",
    "    \n",
    "    :param path: Pathlib Path object or string of the directory to clean.\n",
    "    \"\"\"\n",
    "    dir_path = Path(path)\n",
    "    if dir_path.exists() and dir_path.is_dir():\n",
    "        for item in dir_path.iterdir():\n",
    "            if item.is_dir():\n",
    "                shutil.rmtree(item)  # Recursively delete directory\n",
    "            else:\n",
    "                item.unlink()  # Delete file\n",
    "        print(f\"All contents removed from {dir_path}\")\n",
    "    else:\n",
    "        print(f\"The directory {dir_path} does not exist or is not a directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unique value columns\n",
    "df_meta = df_meta[df_meta.columns[df_meta.nunique() > 1]]\n",
    "\n",
    "# mutual preprocessing\n",
    "df_meta_orig = df_meta_orig[df_meta_orig.columns[df_meta_orig.nunique() > 1]]\n",
    "df_meta_orig['PatientID_num'] = df_meta_orig['PatientID'].str.split('_').str[1:3].str.join('_')\n",
    "df_meta_orig[\"abnormality_type\"] = df_meta_orig['PatientID'].str.split('-').str[0]\n",
    "\n",
    "\n",
    "df_meta['PatientID_num'] = df_meta['PatientID'].str.split('_').str[1:3].str.join('_')\n",
    "df_meta_orig['PatientID_num'] = df_meta_orig['PatientID'].str.split('_').str[1:3].str.join('_')\n",
    "df_meta[\"abnormality_type\"] = df_meta['PatientID'].str.split('-').str[0]\n",
    "df_meta_orig[\"abnormality_type\"] = df_meta_orig['PatientID'].str.split('-').str[0]\n",
    "df_meta = df_meta[df_meta['abnormality_type'] == \"Mass\"]\n",
    "df_meta['PatientID'] = df_meta['PatientID'].str.split('_').str[3:].str.join(\"_\") \n",
    "df_meta[\"abnorm_num\"] = df_meta['PatientID'].str.split('_').str[2]\n",
    "df_meta['abnorm_num'] = df_meta['abnorm_num'].fillna(1) # all NaN are only 1 abnormality\n",
    "df_meta['PatientID'] = df_meta['PatientID'].str.split('_').str[0:2].str.join(\"_\")\n",
    "\n",
    "# fix duplicate column breast density\n",
    "df.loc[df['breast_density'].isna(), 'breast_density'] = df.loc[~df['breast density'].isna(), 'breast density']\n",
    "df['breast_density'] = df['breast_density'].astype('int32')\n",
    "df = df.drop(columns=[\"breast density\"])\n",
    "\n",
    "# # fix column names\n",
    "df_mass.columns, df_calc.columns  = df_mass.columns.str.replace(' ', '_'), df_calc.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "# mass shape limited to most common\n",
    "mass_shape_val = ['OVAL', 'IRREGULAR', 'LOBULATED', 'ROUND']\n",
    "df = df.query(\"mass_shape in @mass_shape_val\")\n",
    "\n",
    "# assessment limited to 0,3,4,5\n",
    "birads_val = [0, 3, 4, 5]\n",
    "df = df.query(\"assessment in @birads_val\")\n",
    "\n",
    "# create masked_cropped column for aiding in dataset split\n",
    "df[\"masked_cropped\"] = df[\"patient_id\"] + \"_\" + \"Mass\" + \"_\" + df[\"left_or_right_breast\"] + \"_\" + df[\"image_view\"] + \"_\" +df[\"abnormality_id\"].astype('str')\n",
    "\n",
    "# Benign without callback = benign\n",
    "df[\"pathology\"] = df[\"pathology\"].replace([\"BENIGN_WITHOUT_CALLBACK\"], \"BENIGN\")\n",
    "\n",
    "# drop unused columns\n",
    "df_meta = df_meta.drop(columns=[\"StudyInstanceUID\", \"TimeStamp\", \"FileSize\", \"abnormality_type\"])\n",
    "df = df.drop(columns=[\"image_file_path\",\"cropped_image_file_path\", \"ROI_mask_file_path\"])\n",
    "\n",
    "df = df[~df['patient_id'].isin([\"P_00016\"])] # doesn't have ROI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for future use\n",
    "df_meta.to_csv(data_dir/'df_meta.csv')\n",
    "df.to_csv(data_dir/\"df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrepencies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No mention of clip limit values\n",
    "2. They state that CBIS-DDSM  \"presents cases in BI-RADS category 2 to 5\"\n",
    "3. Do they use the cropped dataset due to mass shape values also in BiRADS and pathology classification, or the full(+calcification) dataset?\n",
    "5. BiRADS distribution significantly different. Their category 2 is considered as 0.\n",
    "6. \"we resize the detected and segmented ROIs from 256 × 256...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique mass patients with ['OVAL', 'IRREGULAR', 'LOBULATED', 'ROUND'] mass shapes: 778\n",
      "total #patients (+calc): 1566\n",
      "Stated #patients: 1555\n"
     ]
    }
   ],
   "source": [
    "print(f\"unique mass patients with {mass_shape_val} mass shapes: {df_orig.loc[df_orig['mass shape'].isin(mass_shape_val), 'patient_id'].nunique()}\") \n",
    "print(f\"total #patients (+calc): {df_orig['patient_id'].nunique()}\")\n",
    "print(f\"Stated #patients: 1555\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mass lesions mammograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ours: 1592\n",
      "Theirs: 1467\n"
     ]
    }
   ],
   "source": [
    "# all types of mass lesions\n",
    "print(f\"  ours: {df_mass['image_file_path'].nunique()}\\nTheirs: 1467\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pathology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MALIGNANT                  1457\n",
       "BENIGN                     1429\n",
       "BENIGN_WITHOUT_CALLBACK     682\n",
       "Name: pathology, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig[\"pathology\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN       4644\n",
       "MALIGNANT    3900\n",
       "Name: pathology, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented[\"pathology\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which | Benign    |Malignant |\n",
    "------|-----------|----------|\n",
    "Ours  | 4644      | 3900     |\n",
    "Theirs| 4500      | 4302     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    590\n",
       "3    331\n",
       "5    317\n",
       "0    156\n",
       "2     27\n",
       "1      3\n",
       "Name: assessment, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"assessment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mass shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRREGULAR    2784\n",
       "OVAL         2472\n",
       "LOBULATED    2304\n",
       "ROUND         984\n",
       "Name: mass_shape, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented[\"mass_shape\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which | IRREGULAR|  OVAL     |LOBULATED |    ROUND |\n",
    "------|----------|-----------|----------|----------|\n",
    "Ours  | 2784      | 2472     | 2304     | 984      | \n",
    "Theres| 3846      | 2040     |  2112    | 804     |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiRads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3540\n",
       "3    1986\n",
       "5    1902\n",
       "0     936\n",
       "2     162\n",
       "1      18\n",
       "Name: assessment, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented[\"assessment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which | 2        |    3     |        4 |        5 |        6 |\n",
    "------|----------|----------|----------|----------|----------|\n",
    "Ours  | 162      | 1986     | 3540     | 1902     | 0        |\n",
    "Theres| 792      | 1938     |  2328    | 3402     | 0        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all mass masked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients = cropped_list\n",
    "problematic_lst = []\n",
    "new_list = []\n",
    "all_patients_mass = list(df_meta['PatientID_num'].unique())\n",
    "patients = all_patients_mass\n",
    "# patients = [\"P_00016\"]\n",
    "print(f\"proccesing patients {patients[0]} to {patients[-1]}...\")\n",
    "for patient in tqdm(patients, total=len(patients)):\n",
    "    print(f\"patient {patient}:\")\n",
    "    # if patient not in cropped_list:\n",
    "    download_patient(patient)\n",
    "    df_abnorm = df_meta.loc[(df_meta['PatientID_num'] == patient) & (df_meta['SeriesDescription']=='ROI mask images')]\n",
    "    \n",
    "\n",
    "    for row in df_abnorm.iterrows():\n",
    "        out = None\n",
    "        abnormality_type, scan_type=row[1][\"abnormality_type\"], row[1][\"PatientID\"]\n",
    "        abnorm = row[1][\"abnorm_num\"]\n",
    "        abnorm_folder_name = row[1][\"SeriesInstanceUID\"]\n",
    "\n",
    "        df_full = df_meta[(df_meta[\"PatientID_num\"] == patient) & (df_meta['PatientID'] == scan_type) & (df_meta['SeriesDescription'] == 'full mammogram images')]\n",
    "        if len(df_full) !=1:\n",
    "            problematic_lst.append(patient)\n",
    "            break\n",
    "        full_folder_name = df_full.iloc[0]['SeriesInstanceUID']\n",
    "\n",
    "        full_dcm = dcm_dir/patient/full_folder_name/\"1-1.dcm\"\n",
    "        full_pixel = read_dcm(full_dcm)\n",
    "        # print(full_pixel.shape)\n",
    "        abnorm_folder = dcm_dir/patient/abnorm_folder_name\n",
    "        abnorm_dcm_files = list(abnorm_folder.rglob(\"*.dcm\"))\n",
    "        if len(abnorm_dcm_files)>1:\n",
    "            a, b = read_dcm(abnorm_dcm_files[0]), read_dcm(abnorm_dcm_files[1])\n",
    "            mask = a if a.shape > b.shape else b\n",
    "        else:\n",
    "            mask = read_dcm(abnorm_dcm_files[0])\n",
    "        padding = [(0, a_dim - b_dim) for a_dim, b_dim in zip(full_pixel.shape, mask.shape)]\n",
    "        mask_padded = np.pad(mask, padding, mode='constant', constant_values=0)\n",
    "    # for abnorm_dcm in abnorm_dcm_files:\n",
    "    #     abnorm_pixel = read_dcm(abnorm_dcm)\n",
    "        # print(b.shape)\n",
    "        \n",
    "    # if full_pixel.shape == abnorm_pixel.shape:\n",
    "        out = get_cropped_img(full_pixel, mask_padded)\n",
    "        new_name = patient + '_' + abnormality_type + '_' + scan_type + '_' + abnorm + '.png'\n",
    "        img_path = masked_data_dir/new_name\n",
    "        print(\"--------------------\")\n",
    "        print(img_path)\n",
    "        print(\"---------------------\")\n",
    "        cv2.imwrite(str(img_path), out)\n",
    "                # break\n",
    "        \n",
    "        if out is None:\n",
    "            print(f\"failed for {patient}\")\n",
    "            new_list.append(patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Datasets for models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram Equalization\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_angles = [90, 180, 270]\n",
    "clip_limit_values = [2, 10]\n",
    "tileGridSize=(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = masked_data_dir/\"P_00001_Mass_LEFT_CC_1_90.png\"\n",
    "image_cv2 = cv2.imread(str(img_path), cv2.IMREAD_UNCHANGED)\n",
    "b = cv2.equalizeHist(image_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All contents removed from /home/gilb-server/Konstantin/medical/data/augmented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting x6...:   0%|          | 2/1694 [00:00<02:56,  9.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting x6...: 100%|██████████| 1694/1694 [02:14<00:00, 12.56it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_directory(augmented_dir)\n",
    "src_paths = list(masked_data_dir.glob(\"*.png\"))\n",
    "for img_path in tqdm(src_paths, total=len(src_paths), desc=\"Augmenting x6...\"):\n",
    "    with Image.open(img_path) as img:\n",
    "        for rot_angle in rot_angles:\n",
    "            img_rot = img.rotate(rot_angle, expand=True)\n",
    "            dest_path = augmented_dir/(img_path.stem + f\"_{str(rot_angle)}.png\")\n",
    "            img_rot.save(dest_path)\n",
    "\n",
    "        for clip_value in clip_limit_values:\n",
    "            img_np = np.array(img)\n",
    "            img_np = img_np.astype(np.uint16)\n",
    "            clahe = cv2.createCLAHE(clipLimit=clip_value, tileGridSize=tileGridSize)\n",
    "            clahe_image = clahe.apply(img_np)\n",
    "            clahe_pil_image = Image.fromarray(clahe_image)\n",
    "\n",
    "            dest_path = augmented_dir/(img_path.stem + f\"_clahe{clip_value}.png\")\n",
    "            clahe_pil_image.save(dest_path)\n",
    "        dest_file = augmented_dir/img_path.name\n",
    "        shutil.copy2(img_path, dest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create augmented df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented = df.copy()\n",
    "for rot_angle in rot_angles:\n",
    "    df_rot = df.copy()\n",
    "    df_rot['masked_cropped'] = df_rot['masked_cropped'] + f'_{str(rot_angle)}'\n",
    "    df_augmented = pd.concat([df_augmented, df_rot], ignore_index=True)\n",
    "\n",
    "for clip_value in clip_limit_values:\n",
    "    df_clahe = df.copy()\n",
    "    df_clahe['masked_cropped'] = df_clahe['masked_cropped'] + f'_clahe{clip_value}'\n",
    "    df_augmented = pd.concat([df_augmented, df_clahe], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "val_size = 0.5\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file_path in masked_data_dir.glob(\"*clahe*.png\"):\n",
    "#     file_path.unlink()  # Delete the file\n",
    "\n",
    "# for rot_angle in rot_angles:\n",
    "#     for file_path in masked_data_dir.glob(f\"*{rot_angle}*.png\"):\n",
    "#         file_path.unlink()  # Delete the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All contents removed from /home/gilb-server/Konstantin/medical/data/dataset\n",
      "working on assessment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train processing...:  17%|█▋        | 1145/6681 [00:00<00:01, 3871.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train processing...: 100%|██████████| 6681/6681 [00:01<00:00, 3976.86it/s]\n",
      "val processing...: 100%|██████████| 835/835 [00:00<00:00, 4037.43it/s]\n",
      "test processing...: 100%|██████████| 836/836 [00:00<00:00, 3598.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on pathology...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train processing...: 100%|██████████| 6681/6681 [00:01<00:00, 3827.00it/s]\n",
      "val processing...: 100%|██████████| 835/835 [00:00<00:00, 4031.03it/s]\n",
      "test processing...: 100%|██████████| 836/836 [00:00<00:00, 3544.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on mass_shape...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train processing...: 100%|██████████| 6681/6681 [00:01<00:00, 3647.24it/s]\n",
      "val processing...: 100%|██████████| 835/835 [00:00<00:00, 3117.01it/s]\n",
      "test processing...: 100%|██████████| 836/836 [00:00<00:00, 3813.54it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_directory(dataset_dir)\n",
    "df_augmented = df_augmented.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "for task in [\"assessment\", \"pathology\", \"mass_shape\"]:\n",
    "    train_df, temp_df = train_test_split(df_augmented, train_size=train_size, random_state=seed, stratify=df_augmented[task])\n",
    "    val_df, test_df = train_test_split(temp_df, train_size=val_size, random_state=seed, stratify=temp_df[task])\n",
    "    print(f\"working on {task}...\")\n",
    "    for df_type, split in zip([train_df, val_df, test_df], ['train', 'val', 'test']):\n",
    "        \n",
    "        for row in tqdm(df_type.iterrows(), total=len(df_type), desc=f\"{split} processing...\"):\n",
    "            filename = row[1][\"masked_cropped\"] + \".png\"\n",
    "            src_file = augmented_dir/filename\n",
    "\n",
    "            dest_dir = dataset_dir/task/split/str(row[1][task])\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            dest_file = dest_dir/ src_file.name\n",
    "            shutil.copy2(src_file, dest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `cv2` imwrite reduces uint 16 to uint8, use `cv2.imread(str(img_path), cv2.IMREAD_UNCHANGED)`\n",
    "2. `imageio` retain resolution, PIL converts to comfortalbe one (like uint16 -> int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "lr = 0.001\n",
      "Epoch  1\n",
      "lr = 0.001\n",
      "Epoch  2\n",
      "lr = 0.001\n",
      "Epoch  3\n",
      "lr = 0.001\n",
      "Epoch  4\n",
      "lr = 0.001\n",
      "Epoch  5\n",
      "lr = 0.001\n",
      "Epoch  6\n",
      "lr = 0.0001\n",
      "Epoch  7\n",
      "lr = 0.0001\n",
      "Epoch  8\n",
      "lr = 0.0001\n",
      "Epoch  9\n",
      "lr = 0.0001\n",
      "Epoch  10\n",
      "lr = 0.0001\n",
      "Epoch  11\n",
      "lr = 0.0001\n",
      "Epoch  12\n",
      "lr = 1e-05\n",
      "Epoch  13\n",
      "lr = 1e-05\n",
      "Epoch  14\n",
      "lr = 1e-05\n",
      "Epoch  15\n",
      "lr = 1e-05\n",
      "Epoch  16\n",
      "lr = 1e-05\n",
      "Epoch  17\n",
      "lr = 1e-05\n",
      "Epoch  18\n",
      "lr = 1.0000000000000002e-06\n",
      "Epoch  19\n",
      "lr = 1.0000000000000002e-06\n",
      "Epoch  20\n",
      "lr = 1.0000000000000002e-06\n",
      "Epoch  21\n",
      "lr = 1.0000000000000002e-06\n",
      "Epoch  22\n",
      "lr = 1.0000000000000002e-06\n",
      "Epoch  23\n",
      "lr = 1.0000000000000002e-06\n",
      "Epoch  24\n",
      "lr = 1.0000000000000002e-07\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(10, 2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=5, verbose=True)\n",
    "\n",
    "for i in range(25):\n",
    "    print('Epoch ', i)\n",
    "    scheduler.step(1.)    \n",
    "    # print(optimizer.param_groups[0]['lr'])\n",
    "    print(f\"lr = {scheduler.get_last_lr()[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CBIS-DDSM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
